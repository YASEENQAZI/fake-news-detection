# -*- coding: utf-8 -*-
"""App.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OX-WMDTubBLME7HzSjmtPifu2oPwNZw4
"""

# app.py create karna
app_code = """
import streamlit as st
import joblib
import re
import nltk
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer

# Download NLTK resources (only first run)
nltk.download('stopwords')
nltk.download('wordnet')

# Load model and vectorizer
model = joblib.load("fake_news_model.pkl")
vectorizer = joblib.load("tfidf_vectorizer.pkl")

# Preprocessing function
stop_words = set(stopwords.words('english'))
lemmatizer = WordNetLemmatizer()

def preprocess_text(text):
    text = text.lower()
    text = re.sub(r'[^a-z\\\\s]', '', text)
    tokens = text.split()
    tokens = [lemmatizer.lemmatize(w) for w in tokens if w not in stop_words]
    return " ".join(tokens)

# Streamlit App UI
st.title("Fake News Detection App")
st.write("Paste any news article below to check if it is **Fake** or **Real**.")

user_input = st.text_area("Enter News Article Text")

if st.button("Classify"):
    if user_input.strip() == "":
        st.warning("Please enter some text first!")
    else:
        clean_text = preprocess_text(user_input)
        vectorized_text = vectorizer.transform([clean_text])
        prediction = model.predict(vectorized_text)[0]
        if prediction == 1:
            st.success("This article looks **Real News** ðŸ“°")
        else:
            st.error("This article looks **Fake News** ðŸš¨")
"""

with open("app.py", "w") as f:
    f.write(app_code)

# requirements.txt create karna
req_content = "streamlit\nscikit-learn\njoblib\nnltk\n"
with open("requirements.txt", "w") as f:
    f.write(req_content)

print("app.py and requirements.txt created successfully!")